{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEM and SBM Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graspy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import dask\n",
    "from dask.distributed import Client, progress\n",
    "import dask.dataframe as ddf\n",
    "#uncomment when placed into model folder not doc\n",
    "#from .base import BaseGraphEstimator, _calculate_p\n",
    "\n",
    "from scipy.stats import bernoulli, mannwhitneyu, fisher_exact\n",
    "from scipy import stats\n",
    "from scipy.special import expit\n",
    "import pandas as pd \n",
    "import mizani as miz\n",
    "\n",
    "from graspy.simulations import sbm, er_np, er_nm\n",
    "from graspy.plot import heatmap\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from graspy.models.base import BaseGraphEstimator \n",
    "from graspy.utils.utils import (\n",
    "    augment_diagonal,\n",
    "    cartprod,\n",
    "    import_graph,\n",
    "    is_unweighted,\n",
    "    remove_loops,\n",
    "    symmetrize,\n",
    ")\n",
    "from graspy.simulations import siem\n",
    "import sys\n",
    "import plotnine as p9\n",
    "from dfply import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modular_edges(n):\n",
    "    \"\"\"\n",
    "    A function for generating modular sbm edge communities.\n",
    "    \"\"\"\n",
    "    m = int(n/2)\n",
    "    edge_comm = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if ( (i<m) & (j<m)) or ( (i>=m ) & (j>=m) ):\n",
    "                edge_comm[i,j] = 1\n",
    "            else:\n",
    "                edge_comm[i,j] = 2   \n",
    "    return edge_comm\n",
    "\n",
    "def nuis_edges(n):\n",
    "    \"\"\"\n",
    "    A function for generating doubly modular sbm.\n",
    "    \"\"\"\n",
    "    m = int(n/2)\n",
    "    m4 = int(7*n/8)\n",
    "    m3 = int(5*n/8)\n",
    "    m2 = int(3*n/8)\n",
    "    m1 = int(1*n/8)\n",
    "    edge_comm = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if ( (i<m) & (j<m)) or ( (i>=m ) & (j>=m) ):\n",
    "                edge_comm[i,j] = 1\n",
    "            elif (((i >= m3) & (i <= m4)) & ((j >= m1) & (j <= m2))) or (((i >= m1) & (i <= m2)) & ((j >= m3) & (j <= m4))):\n",
    "                edge_comm[i,j] = 3\n",
    "            else:\n",
    "                edge_comm[i,j]=2\n",
    "    return edge_comm\n",
    "    \n",
    "\n",
    "def diag_edges(n):\n",
    "    \"\"\"\n",
    "    A function for generating diagonal SIEM edge communities.\n",
    "    \"\"\"\n",
    "    m = int(n/2)\n",
    "    edge_comm = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if (i == j + m) or (j == i + m):\n",
    "                edge_comm[i,j] = 1\n",
    "            else:\n",
    "                edge_comm[i,j] = 2\n",
    "    return edge_comm\n",
    "\n",
    "            \n",
    "def modular_sbm(n, effect_size=0, weighted=False):\n",
    "    \"\"\"\n",
    "    A function to generate edge assignments for a modular sbm.\n",
    "    \"\"\"\n",
    "    edge_comm = modular_edges(n)\n",
    "    if (weighted == False):\n",
    "        mod = siem(n, [0.5 + effect_size/2, 0.5 - effect_size/2],\n",
    "                   edge_comm=edge_comm, directed = True, loops = True,\n",
    "                   return_labels=True)\n",
    "    else:\n",
    "        mod = siem(n, [1, 1],\n",
    "                   edge_comm=edge_comm, directed = True, loops = True,\n",
    "                   return_labels=True, wt=np.random.normal,\n",
    "                    wtargs=[{\"loc\": 0.5 + effect_size/2, \"scale\": .5},\n",
    "                            {\"loc\": 0.5 - effect_size/2, \"scale\": .5}])\n",
    "    mod = list(mod)\n",
    "    return tuple(mod)\n",
    "\n",
    "def outlier_sbm(n, effect_size=0, outlier=.25, outlier_sc=3):\n",
    "    \"\"\"\n",
    "    A function to generate edge assignments for a modular sbm.\n",
    "    \"\"\"\n",
    "    edge_comm = modular_edges(n)\n",
    "\n",
    "    mod = siem(n, [1, 1],\n",
    "               edge_comm=edge_comm, directed = True, loops = True,\n",
    "               return_labels=True, wt=np.random.normal,\n",
    "                wtargs=[{\"loc\": 0.5 + effect_size/2, \"scale\": .5},\n",
    "                        {\"loc\": 0.5 - effect_size/2, \"scale\": .5}])\n",
    "    mod = list(mod)\n",
    "    mod[0] = mod[0] + (np.multiply(np.random.binomial(n=1, p=outlier, size=n**2),\n",
    "        np.random.normal(loc = 0, scale=outlier_sc, size=n**2))).reshape((n,n))\n",
    "    return tuple(mod)\n",
    "\n",
    "def skew_modular_sbm(n, effect_size=0):\n",
    "    \"\"\"\n",
    "    A function to generate edge weights for a modular sbm,\n",
    "    with skew in the weight distribution.\n",
    "    \"\"\"\n",
    "    C = modular_edges(n)\n",
    "    A = np.zeros((n,n))\n",
    "    A[C == 1] = np.random.beta(5, 5 + effect_size, size=(C == 1).sum())\n",
    "    A[C == 2] = np.random.beta(5 - effect_size, 5, size=(C == 2).sum())\n",
    "    return (A, C)\n",
    "        \n",
    "def diag_siem(n, effect_size=0, weighted=False):\n",
    "    \"\"\"\n",
    "    A function to generate edge assignments for a diagonal siem.\n",
    "    \"\"\"\n",
    "    edge_comm = diag_edges(n)\n",
    "    if (weighted == False):\n",
    "        mod = siem(n, [0.5 + effect_size/2, 0.5 - effect_size/2],\n",
    "                   edge_comm=edge_comm, directed = True, loops = True,\n",
    "                   return_labels=True)\n",
    "    else:\n",
    "        mod = siem(n, [1, 1],\n",
    "                   edge_comm=edge_comm, directed = True, loops = True,\n",
    "                   return_labels=True, wt=np.random.normal,\n",
    "                    wtargs=[{\"loc\": 0.5 + effect_size/2, \"scale\": .5},\n",
    "                            {\"loc\": 0.5 - effect_size/2, \"scale\": .5}])\n",
    "    mod = list(mod)\n",
    "    return tuple(mod)\n",
    "\n",
    "def vcorr_sbm(n, effect_size=0):\n",
    "    \"\"\"\n",
    "    A function to generate a vertex-correlated SBM.\n",
    "    \"\"\"\n",
    "    C = modular_edges(n).flatten()\n",
    "    X = np.zeros((n, n))\n",
    "\n",
    "    Vj = np.tile(range(0, n), (n,1)).flatten()\n",
    "    Vi = np.tile(range(0, n), (n, 1)).transpose().flatten()\n",
    "    # the portion of the design matrix for the vertex assignments\n",
    "    # n elements (1 parameter per vertex) and n^2 entries (1 vector per edge)\n",
    "    X_v=np.zeros((n**2, n))\n",
    "    for i in range(0, len(Vi)):\n",
    "        X_v[i, Vi[i]] = 1\n",
    "        X_v[i, Vj[i]] = 1\n",
    "    # create design matrix with an intercept, an offset for community 1,\n",
    "    # and succeeding columns are the incident vertex ids\n",
    "    X = np.hstack((np.ones((n**2))[:,None], (C == 1)[:,None], X_v))\n",
    "    # coefficients are each vertex is standard normal for the \"amplifying factor\"\n",
    "    B = np.array(np.vstack((np.array([-effect_size/2, effect_size/2])[:,None],\n",
    "                            np.random.uniform(low=-5, high=5, size=n)[:,None])))\n",
    "    # systematic component of the GLM\n",
    "    Sys_comp = X.dot(B)\n",
    "    # convert to probabilities\n",
    "    P = 1/(1 + np.exp(Sys_comp))\n",
    "    # sample the graph\n",
    "    Edges = bernoulli.rvs(P)\n",
    "    # put it into adjacency form\n",
    "    return (Edges.reshape((n, n)), C.reshape((n,n)))\n",
    "\n",
    "def nuisance_sbm(n, effect_size=0, nuis=.7):\n",
    "    \"\"\"\n",
    "    A SBM, with a nuisance community.\n",
    "    \"\"\"\n",
    "    C = nuis_edges(n)\n",
    "    eff = [0.5 + effect_size/2, 0.5 - effect_size/2, nuis]\n",
    "    A = np.zeros((n,n))\n",
    "    for k in range(1, 4):\n",
    "        A[C == k] = np.random.binomial(1, eff[k-1], size=(C == k).sum())\n",
    "    return A, C\n",
    "\n",
    "def corr_sbm(n, effect_size=0, corr=.5):\n",
    "    \"\"\"\n",
    "    A SBM with correlated between-community relationship.\n",
    "    \"\"\"\n",
    "    # start with P=.5\n",
    "    P = 0.5*np.ones((n,n))\n",
    "    # in the upper left and bottom right blocks, make .5 + effect_size/2\n",
    "    P[1:(n/2), 1:(n/2)] = P[1:(n/2), 1:(n/2)] + effect_size/2\n",
    "    P[((n/2)+1):n, ((n/2)+1):n] = P[((n/2)+1):n, ((n/2)+1):n] + effect_size/2\n",
    "    P[1:(n/2), ((n/2)+1):n] = P[1:(n/2), ((n/2)+1):n] - effect_size/2\n",
    "    P[((n/2)+1):n, 1:(n/2)] = P[((n/2)+1):n, 1:(n/2)] - effect_size/2\n",
    "    \n",
    "        \n",
    "def fishers_exact(G, C, alternative='neq'):\n",
    "    \"\"\"\n",
    "    G is a binary graph, C is community assignments.\n",
    "    \"\"\"\n",
    "    if alternative == 'neq':\n",
    "        alternative = \"two-sided\"\n",
    "    T = np.zeros((2,2))\n",
    "    for k in range(0, 2):\n",
    "        T[0,k] = (G[C == (k+1)]).sum()\n",
    "        T[1,k] = len(G[C == (k + 1)]) - T[0,k]\n",
    "    (T, pval) = fisher_exact(T, alternative=alternative)\n",
    "    return(pval)\n",
    "    \n",
    "def lrt(G, C):\n",
    "    G_vec = G.flatten()\n",
    "    C_vec = C.flatten()\n",
    "    model = smf.glm(formula='Edges~Community',\n",
    "                    data=pd.DataFrame({'Edges': G_vec, 'Community': C_vec}),\n",
    "                    family=sm.families.Binomial()).fit()\n",
    "    model_null = smf.glm(formula='Edges~1',\n",
    "                    data=pd.DataFrame({'Edges': G_vec, 'Community': C_vec}),\n",
    "                    family=sm.families.Binomial()).fit()\n",
    "    dof = model_null.df_resid - model.df_resid\n",
    "    lrs = 2*(model.llf - model_null.llf)\n",
    "    lr_pval=stats.chi2.sf(lrs, df=dof)\n",
    "    return(lr_pval)\n",
    "\n",
    "def welch_t(G, C):\n",
    "    A = G[C == 1]\n",
    "    B = G[C == 2]\n",
    "    return(stats.ttest_ind(A, B, equal_var=False)[1])\n",
    "\n",
    "def mww(G, C):\n",
    "    A = G[C == 1]\n",
    "    B = G[C == 2]\n",
    "    return(stats.mannwhitneyu(A, B, alternative='two-sided')[1])\n",
    "\n",
    "def uncorr_perm(G, C, nperm=200):\n",
    "    G_vec = G.flatten()\n",
    "    C_vec = C.flatten()\n",
    "    if len(np.unique(G_vec)) > 2:\n",
    "        wt_fn = np.median\n",
    "    else:\n",
    "        wt_fn = np.mean\n",
    "    Ta = np.abs(wt_fn(G_vec[C_vec == 1]) - wt_fn(G_vec[C_vec == 2]))\n",
    "    T_null = np.zeros((nperm))\n",
    "    for i in range(0, nperm):\n",
    "        C_null = np.random.choice(C_vec, size=len(C_vec), replace=False)\n",
    "        T_null[i] = wt_fn(G_vec[C_null == 1]) - wt_fn(G_vec[C_null == 2])\n",
    "    T_null = np.abs(T_null)\n",
    "    return((sum(T_null > Ta)+1)/(nperm + 1))\n",
    "\n",
    "def corr_lrt(G, C):\n",
    "    G_vec = G.flatten()\n",
    "    Vi = np.tile(range(0, C.shape[0]), (C.shape[0],1)).flatten()\n",
    "    Vj = np.tile(range(0, C.shape[0]), (C.shape[0], 1)).transpose().flatten()\n",
    "    C_vec = C.flatten()\n",
    "    edge_df = pd.DataFrame({'Edges': G_vec, 'Community': C_vec,\n",
    "                            'Vi': Vi, 'Vj': Vj})\n",
    "    model = smf.glm(formula='Edges~Community + Vi + Vj',\n",
    "                    data=edge_df, family=sm.families.Binomial()).fit()\n",
    "    model_null = smf.glm(formula='Edges~Vi + Vj',\n",
    "                    data=edge_df, family=sm.families.Binomial()).fit()\n",
    "    dof = model_null.df_resid - model.df_resid\n",
    "    lrs = 2*(model.llf - model_null.llf)\n",
    "    lr_pval=stats.chi2.sf(lrs, df=dof)\n",
    "    return(lr_pval)\n",
    "\n",
    "def nlrt(G):\n",
    "    n = G.shape[0]\n",
    "    G_vec = G.flatten()\n",
    "    C = nuis_edges(n)\n",
    "    C_vec = C.flatten()\n",
    "    edge_df = pd.DataFrame({'Edges': G_vec, 'Community': C_vec})\n",
    "    edge_df[\"Community\"] = edge_df[\"Community\"].astype(\"category\")\n",
    "    model = smf.glm(formula='Edges~Community',\n",
    "                    data=edge_df, family=sm.families.Binomial()).fit()\n",
    "    model_null = smf.glm(formula='Edges~(Community == 2)',\n",
    "                    data=edge_df, family=sm.families.Binomial()).fit()\n",
    "    dof = model_null.df_resid - model.df_resid\n",
    "    lrs = 2*(model.llf - model_null.llf)\n",
    "    lr_pval=stats.chi2.sf(lrs, df=dof)\n",
    "    return(lr_pval)\n",
    "\n",
    "def gather_matrix(mtx, weighted=\"\", gr_type=\"\"):\n",
    "    \"\"\"\n",
    "    Converts a matrix to a pandas dataframe\n",
    "    \"\"\"\n",
    "    pd_mtx = pd.DataFrame(mtx)\n",
    "    pd_mtx.columns = np.arange(1, mtx.shape[0] + 1, 1)\n",
    "    pd_mtx >>= gather('Column', 'Weight', add_id=True)\n",
    "    pd_mtx=pd_mtx.rename(columns={\"_ID\": \"Row\"})\n",
    "    pd_mtx[\"Weighting\"]=weighted\n",
    "    pd_mtx[\"Method\"] = gr_type\n",
    "    pd_mtx[\"Row\"] = pd_mtx[\"Row\"] + 1\n",
    "    return(pd_mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the color for each test statistic\n",
    "test_stat_cols = {'FET': 'red',\n",
    "                  'LRT': 'teal',\n",
    "                  'MWW': 'blue',\n",
    "                  'PT': 'green',\n",
    "                  'WT': 'orange',\n",
    "                  'rLRT': 'purple'}\n",
    "\n",
    "# an array tracking the test statistics themselves\n",
    "test_stats = {'FET': fishers_exact,\n",
    "              'LRT': lrt,\n",
    "              'MWW': mww,\n",
    "              'PT': uncorr_perm,\n",
    "              'WT': welch_t,\n",
    "              'rLRT': corr_lrt}\n",
    "\n",
    "# an array for when to use different test statistics\n",
    "test_stat_use = {'FET': ['Unweighted'],\n",
    "                'LRT': ['Unweighted'],\n",
    "                'MWW': ['Unweighted', 'Weighted'],\n",
    "                'PT': ['Unweighted', 'Weighted'],\n",
    "                'WT': ['Unweighted', 'Weighted'],\n",
    "                'rLRT': ['Unweighted'],\n",
    "                'nLRT': ['Unweighted']}\n",
    "\n",
    "simulations = {\n",
    "    'Unweighted': {'SIEM': {'fn': diag_siem, 'eff_sz': np.linspace(0, .4, 10), 'kwarg': {\"weighted\": False}},\n",
    "                   'SBM': {'fn': modular_sbm, 'eff_sz': np.linspace(0, .2, 10), 'kwarg': {\"weighted\": False}},\n",
    "                   'rSBM': {'fn': vcorr_sbm, 'eff_sz': np.linspace(0, 3, 10), 'kwarg': None},\n",
    "                   'nSBM': {'fn': nuisance_sbm, 'eff_sz': np.linspace(0, .5, 10), 'kwarg': None}},\n",
    "    'Weighted': {'SIEM': {'fn': diag_siem, 'eff_sz': np.linspace(0, .3, 10), 'kwarg': {\"weighted\": True}}, \n",
    "                 'SBM': {'fn': modular_sbm, 'eff_sz': np.linspace(0, .2, 10), 'kwarg': {\"weighted\": True}},\n",
    "                 'SSBM': {'fn': skew_modular_sbm, 'eff_sz': np.linspace(0, 2, 10), 'kwarg': None},\n",
    "                 'oSBM': {'fn': outlier_sbm, 'eff_sz': np.linspace(0, .2, 10), 'kwarg': {\"outlier\": .3}}}\n",
    "}\n",
    "\n",
    "nrep = 100\n",
    "ncores = 6\n",
    "nvertices = np.round(np.linspace(20, 100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(threads_per_worker=1, n_workers=ncores)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = []\n",
    "for weighting, sims in simulations.items():\n",
    "    for sim_name, sim in sims.items():\n",
    "        for es in sim[\"eff_sz\"]:\n",
    "            for n in nvertices:\n",
    "                for i in range(nrep):\n",
    "                    exps.append([sim_name, weighting, n, es, i])\n",
    "sim_exps = pd.DataFrame(exps, columns=[\"Simulation\", \"Weighting\", \"n\", \"Effect_Size\", \"i\"])\n",
    "sim_exps[\"n\"] = sim_exps[\"n\"].astype(int)\n",
    "print(sim_exps.head())\n",
    "print(sim_exps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(row):\n",
    "    # generate simulation using the dictionary defined above\n",
    "    sim_dict = simulations[row[\"Weighting\"]][row[\"Simulation\"]]\n",
    "    if sim_dict[\"kwarg\"] is not None:\n",
    "        (A, C) = sim_dict[\"fn\"](row[\"n\"], row[\"Effect_Size\"], **sim_dict[\"kwarg\"])\n",
    "    else:\n",
    "        (A, C) = sim_dict[\"fn\"](row[\"n\"], row[\"Effect_Size\"])\n",
    "    # run sim on all test statistics\n",
    "    p_vals = []\n",
    "    stat_names = []\n",
    "    for test_name, test in test_stats.items():\n",
    "        # check if statistic is appropriate for the setting\n",
    "        if row[\"Weighting\"] in test_stat_use[test_name]:\n",
    "            try:\n",
    "                pval = test(A, C)\n",
    "                p_vals.append(pval)\n",
    "                stat_names.append(test_name)\n",
    "            except:\n",
    "                ex_str = \"Failed Test: {}, Simulation: {}, n: {}, Effect Size: {}\"\n",
    "                print(ex_str.format(test_name, row[\"Simulation\"], row[\"n\"], row[\"Effect_Size\"]))\n",
    "                p_vals.append(float(\"NaN\"))\n",
    "        else:\n",
    "            p_vals.append(float(\"NaN\"))\n",
    "    return tuple([row[\"Simulation\"], row[\"Weighting\"], row[\"n\"],\n",
    "                 row[\"Effect_Size\"], row[\"i\"], *p_vals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_exps = ddf.from_pandas(sim_exps, npartitions=10)\n",
    "sim_results = sim_exps.apply(lambda x: run_exp(x), axis=1, result_type='expand',\n",
    "                             meta={0: str, 1: str, 2: int, 3: float, 4: int,\n",
    "                                   5: float, 6: float, 7: float, 8: float, 9: float, 10: float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = sim_results.compute(scheduler=\"multiprocessing\")\n",
    "sim_results = sim_results.rename(columns={0: \"Simulation\", 1: \"Weighting\", 2: \"n\", 3: \"Effect_Size\",\n",
    "                                          4: \"i\", 5: \"FET\", 6: \"LRT\", 7: \"MWW\", 8: \"PT\",\n",
    "                                          9: \"WT\", 10: \"rLRT\"})\n",
    "sim_results.to_pickle('./data/singlegraph_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_results = pd.read_pickle('./data/singlegraph_results.pkl')\n",
    "sim_results >>= gather('Test', 'p_val', ['FET', 'LRT', 'MWW', 'PT', 'WT', 'rLRT'])\n",
    "sim_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold and compute power\n",
    "@make_symbolic\n",
    "def purge_nan(series):\n",
    "    return np.invert(np.isnan(series))\n",
    "\n",
    "@make_symbolic\n",
    "def std_err(series):\n",
    "    return np.std(series)/len(series)\n",
    "alpha = .05\n",
    "power_results = sim_results >> mask(purge_nan(X.p_val)) >> group_by(\n",
    "    \"Simulation\", \"Weighting\", \"n\", \"Effect_Size\", \"Test\"\n",
    "    ) >> mutate(outcome=(X.p_val < alpha).astype(float)\n",
    "    ) >> summarize(power=X.outcome.mean(), power_stderr=std_err(X.outcome)\n",
    "    ) >> group_by(\n",
    "        \"Simulation\", \"Weighting\", \"n\"\n",
    "    ) >> mutate(  # normalize the effect size so they are all on the same scale\n",
    "        Effect_Size=np.around((X.Effect_Size - np.min(X.Effect_Size))/(np.max(X.Effect_Size)-np.min(X.Effect_Size)),\n",
    "                             decimals=3)\n",
    "    )\n",
    "power_results[\"n\"] = power_results[\"n\"].astype('category')\n",
    "power_results[\"n\"].cat.reorder_categories(nvertices.astype(int), inplace=True)\n",
    "power_results[\"Effect_Size\"] = power_results[\"Effect_Size\"].astype('category')\n",
    "power_results[\"Effect_Size\"].cat.reorder_categories(\n",
    "    np.sort(np.unique(power_results[\"Effect_Size\"])), inplace=True)\n",
    "power_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unweighted Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_results = power_results >> mask(X.Weighting == \"Unweighted\")\n",
    "\n",
    "uw_sim_power_plt = (p9.ggplot(data=uw_results, mapping=p9.aes(x=\"n\", y=\"Effect_Size\", fill=\"power\"))\n",
    " + p9.geom_tile()\n",
    " + p9.facet_grid(\"Simulation ~ Test\")\n",
    " + p9.xlab(\"Number of Vertices\")\n",
    " + p9.ylab(\"Effect Size\")\n",
    " + p9.scale_fill_gradient(high=\"green\", low=\"red\", name=\"Power\")\n",
    " + p9.scale_x_discrete(breaks=[20, 100])\n",
    " + p9.scale_y_discrete(breaks=[0, 1])\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(9, 4.5), strip.text.y = p9.element_blank())\n",
    " + p9.ggtitle(\"(I) Unweighted Power Plot\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_dat = pd.concat([gather_matrix(modular_sbm(50, effect_size=.5, weighted=False)[0], gr_type=\"SBM\"),\n",
    "           gather_matrix(diag_siem(50, effect_size=.8, weighted=False)[0], gr_type=\"SIEM\"),\n",
    "           gather_matrix(vcorr_sbm(50, effect_size=8)[0], gr_type=\"rSBM\")])\n",
    "gr_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_sim_plt = (p9.ggplot(data=gr_dat, mapping=p9.aes(x=\"factor(Row)\", y=\"factor(Column)\", fill=\"factor(Weight)\"))\n",
    " + p9.geom_tile()\n",
    " + p9.facet_grid(\"Method~\", switch=\"y\")\n",
    " + p9.xlab(\"Vertex 1\")\n",
    " + p9.ylab(\"Vertex 2\")\n",
    " + p9.scale_x_discrete(breaks=[1, 50])\n",
    " + p9.scale_y_reverse(breaks=[1, 50], expand=[0,])\n",
    " + p9.scale_fill_discrete(name=\"Edge\")\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(1.5, 4.5))\n",
    " + p9.ggtitle(\"(I) Simulation Plot\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power (fixed $n$) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_power_fixn_plt = uw_results >> mask(X.n == 56)\n",
    "uw_sim_(p9.ggplot(data=power_fixed_dat, mapping=p9.aes(x=\"Effect_Size\", y=\"power\", \n",
    "                                                color=\"factor(Test)\", group=\"factor(Test)\"))\n",
    " + p9.geom_line()\n",
    " + p9.facet_grid(\"Simulation~\")\n",
    " + p9.xlab(\"Relative Effect Size\")\n",
    " + p9.ylab(\"Power\")\n",
    " + p9.scale_x_discrete(breaks=[0, 0.5, 1])\n",
    " + p9.scale_y_continuous(limits=[0, 1], breaks=[0, 1])\n",
    " + p9.scale_color_discrete(name=\"Test\")\n",
    " + p9.geom_hline(mapping=p9.aes(yintercept=alpha))\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(1.5, 4.5), strip.text.y = p9.element_blank())\n",
    " + p9.ggtitle(\"(III) Power Plots, n=56\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Plots\n",
    "\n",
    "## Power Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_results = power_results >> mask(X.Weighting == \"Weighted\")\n",
    "\n",
    "(p9.ggplot(data=wt_results, mapping=p9.aes(x=\"n\", y=\"Effect_Size\", fill=\"power\"))\n",
    " + p9.geom_tile()\n",
    " + p9.facet_grid(\"Simulation ~ Test\")\n",
    " + p9.xlab(\"Number of Vertices\")\n",
    " + p9.ylab(\"Effect Size\")\n",
    " + p9.scale_fill_gradient(high=\"green\", low=\"red\", name=\"Power\")\n",
    " + p9.scale_x_discrete(breaks=[20, 100])\n",
    " + p9.scale_y_discrete(breaks=[0, 1])\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(4.5, 6))\n",
    " + p9.ggtitle(\"(II) Weighted Power Plot\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_dat = pd.concat([gather_matrix(modular_sbm(50, effect_size=.5, weighted=True)[0], gr_type=\"SBM\"),\n",
    "           gather_matrix(diag_siem(50, effect_size=.8, weighted=True)[0], gr_type=\"SIEM\"),\n",
    "           gather_matrix(skew_modular_sbm(50, effect_size=3)[0], gr_type=\"SSBM\"),\n",
    "           gather_matrix(outlier_sbm(50, effect_size=.8, outlier=.4, outlier_sc=1.5)[0], gr_type=\"oSBM\")])\n",
    "gr_dat >>= group_by(\"Method\") >> mutate(Weight=(X.Weight - np.min(X.Weight))/(np.max(X.Weight) - np.min(X.Weight)))\n",
    "gr_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=gr_dat, mapping=p9.aes(x=\"factor(Row)\", y=\"factor(Column)\", fill=\"Weight\"))\n",
    " + p9.geom_tile()\n",
    " + p9.facet_grid(\"Method~\")\n",
    " + p9.xlab(\"Vertex 1\")\n",
    " + p9.ylab(\"Vertex 2\")\n",
    " + p9.scale_x_discrete(breaks=[1, 50])\n",
    " + p9.scale_y_reverse(breaks=[1, 50])\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(1.5, 6))\n",
    " + p9.ggtitle(\"(I) Simulation Plot\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power (fixed $n$) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_fixed_dat = wt_results >> mask(X.n == 56)\n",
    "(p9.ggplot(data=power_fixed_dat, mapping=p9.aes(x=\"Effect_Size\", y=\"power\", \n",
    "                                                color=\"factor(Test)\", group=\"factor(Test)\"))\n",
    " + p9.geom_line()\n",
    " + p9.facet_grid(\"Simulation~\")\n",
    " + p9.xlab(\"Relative Effect Size\")\n",
    " + p9.ylab(\"Power\")\n",
    " + p9.scale_x_discrete(breaks=[0, 0.5, 1])\n",
    " + p9.scale_y_continuous(limits=[0, 1], breaks=[0, 1])\n",
    " + p9.scale_color_discrete(name=\"Test\")\n",
    " + p9.geom_hline(mapping=p9.aes(yintercept=alpha))\n",
    " + p9.theme_bw()\n",
    " + p9.theme(figure_size=(1.5, 6))\n",
    " + p9.ggtitle(\"(III) Power Plots, n=56\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graspy",
   "language": "python",
   "name": "graspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
