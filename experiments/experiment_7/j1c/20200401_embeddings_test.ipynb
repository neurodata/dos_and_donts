{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/miniconda3/envs/dnd/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from hyppo.ksample import Hotelling, KSample\n",
    "\n",
    "from src import generate_binary_sbms, estimate_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(\n",
    "    m, block_1, block_2, p, delta, n_components, reps, tests, alpha=0.05\n",
    "):\n",
    "    total_n = block_1 + block_2\n",
    "\n",
    "    omni_corrects = np.zeros((reps, 2, len(tests)))\n",
    "    mase_corrects = np.zeros((reps, 2, len(tests)))\n",
    "\n",
    "    for i in np.arange(reps).astype(int):\n",
    "        pop1, pop2, true_labels = generate_binary_sbms(\n",
    "            m=m, block_1=block_1, block_2=block_2, p=p, delta=delta\n",
    "        )\n",
    "\n",
    "        for method in [\"omni\", \"mase\"]:\n",
    "            embeddings = estimate_embeddings(\n",
    "                pop1, pop2, method, n_components, sample_space=True\n",
    "            )\n",
    "            for idx, j in enumerate([0, 19]):\n",
    "                for k, test in enumerate(tests):\n",
    "                    X_nodes = embeddings[:m, j, :]\n",
    "                    Y_nodes = embeddings[m:, j, :]\n",
    "                    try:\n",
    "                        res = test.test(\n",
    "                            embeddings[:m, j, :], embeddings[m:, j, :], reps=500\n",
    "                        )\n",
    "                        pval = res[1]\n",
    "                        if np.isnan(res[1]):\n",
    "                            pval = 1\n",
    "                    except:\n",
    "                        pval = 1\n",
    "\n",
    "                    if method == \"mase\":\n",
    "                        mase_corrects[i, idx, k] = pval\n",
    "                    else:\n",
    "                        omni_corrects[i, idx, k] = pval\n",
    "\n",
    "    omni_powers = (omni_corrects <= (alpha / total_n)).mean(axis=0)\n",
    "    mase_powers = (mase_corrects <= (alpha / total_n)).mean(axis=0)\n",
    "\n",
    "    to_append = [m, p, delta, *omni_powers.reshape(-1), *mase_powers.reshape(-1)]\n",
    "    return to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 50\n",
    "\n",
    "block_1 = 5  # different probability\n",
    "block_2 = 15\n",
    "p = 0.5\n",
    "deltas = np.linspace(0, 1 - p, spacing + 1)\n",
    "n_components = 2\n",
    "reps = 50\n",
    "ms = np.linspace(0, 250, spacing + 1)[1:].astype(int)\n",
    "tests = [KSample(\"MGC\"), Hotelling()]\n",
    "\n",
    "partial_func = partial(\n",
    "    run_experiment,\n",
    "    block_1=block_1,\n",
    "    block_2=block_2,\n",
    "    p=p,\n",
    "    reps=reps,\n",
    "    n_components=n_components,\n",
    "    tests=tests\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 96 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  96 tasks      | elapsed: 157.5min\n",
      "[Parallel(n_jobs=-1)]: Done 258 tasks      | elapsed: 250.8min\n",
      "[Parallel(n_jobs=-1)]: Done 575 out of 638 | elapsed: 498.9min remaining: 54.7min\n",
      "[Parallel(n_jobs=-1)]: Done 638 out of 638 | elapsed: 519.8min finished\n"
     ]
    }
   ],
   "source": [
    "args = [dict(m=m, delta=delta) for m, delta in product(ms, deltas)]\n",
    "args = args[task::4]\n",
    "args = sum(zip(reversed(args), args), ())[: len(args)]\n",
    "\n",
    "res = Parallel(n_jobs=-1, verbose=5)(delayed(partial_func)(**arg) for arg in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"m\",\n",
    "    \"p\",\n",
    "    \"delta\",\n",
    "    *[f\"omni_power_{t}_{i+1}\" for i in [0, 19] for t in ['mgc', 'hotelling']],\n",
    "    *[f\"mase_power_{t}_{i+1}\" for i in [0, 19] for t in ['mgc', 'hotelling']],\n",
    "]\n",
    "res_df = pd.DataFrame(res, columns=cols)\n",
    "res_df = res_df.sort_values(by=[\"m\", \"delta\"])\n",
    "res_df.to_csv(f\"./results/2020401_weighted_correct_nodes_{task}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
