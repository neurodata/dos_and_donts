{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import graspy\n",
    "from graspy.utils import symmetrize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import truncnorm, ks_2samp\n",
    "from scipy.optimize import fmin_slsqp\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from twins import load_dataset\n",
    "from src import generate_truncnorm_sbms, compute_pr_at_k\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = load_dataset(modality='fmri', parcellation='desikan_res-2x2x2', preprocess=None, ptr=None)[0]\n",
    "\n",
    "df = pd.read_csv('../../../../twins/data/raw/unrestricted_jaewonc78_1_20_2019_23_7_58.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = []\n",
    "for sub in graphs.keys():\n",
    "    gender.append(df[df.Subject == int(sub)]['Gender'].values[0])\n",
    "    \n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(gender)\n",
    "# 0 is female, 1 is male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([407, 330]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_graphs = []\n",
    "female_graphs = []\n",
    "\n",
    "for idx, (sub, graph) in enumerate(graphs.items()):\n",
    "    if labels[idx] == 1:\n",
    "        male_graphs.append(graph)\n",
    "    else:\n",
    "        female_graphs.append(graph)\n",
    "        \n",
    "male_graphs = np.array(male_graphs)\n",
    "female_graphs = np.array(female_graphs)\n",
    "\n",
    "male_graphs_mean = male_graphs.mean(axis=0)\n",
    "female_graphs_mean = female_graphs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estiamate mean and variance of truncnorm for each edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_params(data):\n",
    "    def func(p, r, xa, xb):\n",
    "        return truncnorm.nnlf(p, r)\n",
    "\n",
    "    def constraint(p, r, xa, xb):\n",
    "        a, b, loc, scale = p\n",
    "        return np.array([a*scale + loc - xa, b*scale + loc - xb])\n",
    "\n",
    "    xa, xb = 0, 1\n",
    "\n",
    "    loc_guess = data.mean()\n",
    "    scale_guess = data.std()\n",
    "    \n",
    "    a_guess = (xa - loc_guess) / scale_guess\n",
    "    b_guess = (xb - loc_guess) / scale_guess\n",
    "    p0 = [a_guess, b_guess, loc_guess, scale_guess]\n",
    "\n",
    "    a, b, mean, std = fmin_slsqp(func, p0, f_eqcons=constraint, args=(data, xa, xb),\n",
    "                     iprint=False, iter=1000)\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 322 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 672 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1122 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1672 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2415 out of 2415 | elapsed:   16.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 522 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1045 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1503 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2056 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2415 out of 2415 | elapsed:   18.4s finished\n"
     ]
    }
   ],
   "source": [
    "verts = male_graphs.shape[-1]\n",
    "\n",
    "res = Parallel(-1, verbose=1)(\n",
    "    delayed(estimate_params)(male_graphs[:, i, j]) for i in range(verts) for j in range(i+1, verts)\n",
    ")\n",
    "\n",
    "res2 = Parallel(-1, verbose=1)(\n",
    "    delayed(estimate_params)(female_graphs[:, i, j]) for i in range(verts) for j in range(i+1, verts)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute empirical trustworthiness using the estimated parameters as inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_statistic(test, pop1, pop2):\n",
    "    if test.__name__ == \"ttest_ind\":\n",
    "        test_statistics, pvals = ttest_ind(pop1, pop2, axis=0)\n",
    "        np.nan_to_num(test_statistics, copy=False)\n",
    "        np.nan_to_num(pvals, copy=False)\n",
    "    else:  # for other tests, do by edge\n",
    "        n = pop1.shape[-1]\n",
    "        test_statistics = np.zeros((n, n))\n",
    "        pvals = np.zeros((n, n))\n",
    "\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                x_ij = pop1[:, i, j]\n",
    "                y_ij = pop2[:, i, j]\n",
    "\n",
    "                if test.__name__ == \"multiscale_graphcorr\":\n",
    "                    tmp, pval, _ = test(x_ij, y_ij, is_twosamp=True, reps=1)\n",
    "                else:\n",
    "                    tmp, pval = test(x_ij, y_ij)\n",
    "\n",
    "                test_statistics[i, j] = tmp\n",
    "                pvals[i, j] = pval\n",
    "\n",
    "        test_statistics = symmetrize(test_statistics, method=\"triu\")\n",
    "        pvals = symmetrize(pvals, method=\"triu\")\n",
    "\n",
    "    return test_statistics, pvals\n",
    "\n",
    "def run_experiment(mean_1, var_1, mean_2, var_2, \n",
    "                   samp_1=330, samp_2=407,\n",
    "                   test=ks_2samp, \n",
    "                   block_1=5, block_2=15,\n",
    "                   a=0, b=1, reps=100):\n",
    "\n",
    "    if mean_1 is None or mean_2 is None:\n",
    "        return [m, mean_1, mean_2, var_1, var_2, 0, 0]\n",
    "    \n",
    "       \n",
    "    pop1, _, _ = generate_truncnorm_sbms(samp_1, block_1, block_2, mean_1, mean_2, var_1, var_2, a=a, b=b)\n",
    "    _, pop2, _ = generate_truncnorm_sbms(samp_2, block_1, block_2, mean_1, mean_2, var_1, var_2, a=a, b=b)\n",
    "\n",
    "    precisions, recalls = np.zeros((2, reps))\n",
    "    for i in range(reps):\n",
    "        test_statistics, pvalues = compute_statistic(test, pop1, pop2)\n",
    "        precision, recall = compute_pr_at_k(\n",
    "            k=[10], true_labels=true_labels, pvalues=pvalues\n",
    "        )\n",
    "        precisions[i] = precision\n",
    "        recalls[i] = recall\n",
    "        \n",
    "    return [m, mean_1, mean_2, var_1, var_2, *precisions.mean(), *recalls.mean()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "res_arr = np.hstack([res, res2])\n",
    "args = [\n",
    "    dict(mean_1=a, var_1=b**2, mean_2=c, var_2=d**2) \n",
    "    for (a, b, c, d) in res_arr\n",
    "]\n",
    "res = Parallel(n_jobs=-1, verbose=5)(delayed(run_experiment)(**arg) for arg in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
