{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/miniconda3/envs/dnd/lib/python3.8/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from graspy.cluster import GaussianCluster\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import mannwhitneyu, ttest_ind, ks_2samp\n",
    "\n",
    "from src import generate_truncnorm_sbms_with_communities, estimate_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_community(embeddings, n_clusters):\n",
    "    predicted_labels = (\n",
    "        GaussianCluster(n_clusters, n_clusters, \"all\").fit_predict(embeddings) + 1\n",
    "    )\n",
    "\n",
    "    # ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "    return predicted_labels\n",
    "\n",
    "def compute_statistic(tests, pop1, pop2):\n",
    "    res = np.zeros(len(tests))\n",
    "\n",
    "    for idx, test in enumerate(tests):\n",
    "        if test.__name__ == \"multiscale_graphcorr\":\n",
    "            statistic, pval, _ = test(pop1, pop2, reps=250, is_twosamp=True)\n",
    "        elif test.__name__ == \"test\":\n",
    "            statistic, pval = test(pop1, pop2, reps=250)\n",
    "        else:  # for other tests, do by edge\n",
    "            statistic, pval = test(pop1, pop2)\n",
    "        res[idx] = pval\n",
    "\n",
    "    return res\n",
    "\n",
    "def run_experiment(\n",
    "    m,\n",
    "    block_1,\n",
    "    block_2,\n",
    "    mean_1,\n",
    "    mean_2,\n",
    "    var_1,\n",
    "    var_2,\n",
    "    mean_delta,\n",
    "    var_delta,\n",
    "    n_clusters,\n",
    "    reps,\n",
    "    tests,\n",
    "):\n",
    "    total_n = block_1 + block_2\n",
    "    r, c = np.triu_indices(total_n, k=1)\n",
    "\n",
    "    omni_res = np.zeros((reps, len(n_clusters), 2, len(tests)))\n",
    "    mase_res = np.zeros((reps, len(n_clusters), 2, len(tests)))\n",
    "\n",
    "    for i in np.arange(reps).astype(int):\n",
    "        pop1, pop2, true_labels = generate_truncnorm_sbms_with_communities(\n",
    "            m=m,\n",
    "            block_1=block_1,\n",
    "            block_2=block_2,\n",
    "            mean_1=mean_1,\n",
    "            mean_2=mean_2,\n",
    "            var_1=var_1,\n",
    "            var_2=var_2,\n",
    "            mean_delta=mean_delta,\n",
    "            var_delta=var_delta,\n",
    "        )\n",
    "        pop1_edges = pop1[:, r, c]\n",
    "        pop2_edges = pop2[:, r, c]\n",
    "        true_edges = (true_labels[:, None] + true_labels[None, :])[r, c]\n",
    "\n",
    "        for method in [\"mase\", \"omni\"]:\n",
    "            embeddings = estimate_embeddings(pop1, pop2, method, 2)\n",
    "\n",
    "            for k_idx, k in enumerate(n_clusters):\n",
    "                predicted_labels = estimate_community(embeddings, k)\n",
    "                predicted_edge_labels = (\n",
    "                    predicted_labels[:, None] * predicted_labels[None, :]\n",
    "                )[\n",
    "                    r, c\n",
    "                ]  # vectorize to uppper triu\n",
    "                \n",
    "                \n",
    "                cluster_labels = np.unique(predicted_edge_labels)\n",
    "                communitity_pvals = np.zeros((np.unique(cluster_labels).size, len(tests)))\n",
    "\n",
    "                for cdx, cluster_label in enumerate(cluster_labels):\n",
    "                    tmp_labels = predicted_edge_labels == cluster_label\n",
    "                    tmp_pop1_edges = pop1_edges[:, tmp_labels].ravel()\n",
    "                    tmp_pop2_edges = pop2_edges[:, tmp_labels].ravel()\n",
    "\n",
    "                    pvals = compute_statistic(tests, tmp_pop1_edges, tmp_pop2_edges)\n",
    "#                     for p_idx, pval in enumerate(pvals):\n",
    "#                         if pval <= 0.05:\n",
    "#                             sig_edges[p_idx][tmp_labels] = 1\n",
    "                    communitity_pvals[cdx] = pvals\n",
    "                \n",
    "                sig_edges = np.zeros((len(tests), total_n, total_n))[:, r, c]\n",
    "                \n",
    "                for u in range(len(tests)):\n",
    "                    tmp_pvals = communitity_pvals[:, u]\n",
    "                    sig_comm = cluster_labels[np.argsort(tmp_pvals, kind='stable')[0]]\n",
    "                    sig_edges[u, predicted_edge_labels == sig_comm] = 1\n",
    "\n",
    "                prec = (sig_edges[:, true_edges == 0]).sum(axis=1) / sig_edges.sum(\n",
    "                    axis=1\n",
    "                )\n",
    "                np.nan_to_num(prec, False)\n",
    "                recall = (sig_edges[:, true_edges == 0]).sum(axis=1) / (\n",
    "                    true_edges == 0\n",
    "                ).sum(axis=0)\n",
    "\n",
    "                if method == \"mase\":\n",
    "                    mase_res[i, k_idx, :] = np.array((prec, recall))\n",
    "                else:\n",
    "                    omni_res[i, k_idx, :] = np.array((prec, recall))\n",
    "\n",
    "    omni_res = omni_res.mean(axis=0).reshape(-1)\n",
    "    mase_res = mase_res.mean(axis=0).reshape(-1)\n",
    "\n",
    "    to_append = [\n",
    "        m,\n",
    "        mean_1,\n",
    "        mean_2,\n",
    "        var_1,\n",
    "        var_2,\n",
    "        mean_delta,\n",
    "        var_delta,\n",
    "        *omni_res,\n",
    "        *mase_res,\n",
    "    ]\n",
    "    return to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = 50\n",
    "\n",
    "block_1 = 25  # different probability\n",
    "block_2 = 25\n",
    "mean_1 = 0\n",
    "mean_2 = 0\n",
    "var_1 = 0.25\n",
    "var_2 = 0.25\n",
    "mean_deltas = np.linspace(0, 1 , spacing + 1)\n",
    "#var_deltas = np.linspace(var_1, 3, spacing + 1)\n",
    "var_delta = 0\n",
    "reps = 50\n",
    "n_clusters = [2]\n",
    "ms = np.linspace(0, 250, spacing + 1)[1:].astype(int)\n",
    "\n",
    "tests = [ks_2samp, mannwhitneyu, ttest_ind]\n",
    "\n",
    "partial_func = partial(\n",
    "    run_experiment,\n",
    "    block_1=block_1,\n",
    "    block_2=block_2,\n",
    "    mean_1=mean_1,\n",
    "    mean_2=mean_2,\n",
    "    var_1=var_1,\n",
    "    var_2=var_2,\n",
    "    var_delta=var_delta,\n",
    "    #mean_delta=mean_delta,\n",
    "    n_clusters=n_clusters,\n",
    "    reps=reps,\n",
    "    tests=tests,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 128 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 136 tasks      | elapsed: 125.2min\n",
      "[Parallel(n_jobs=-1)]: Done 256 tasks      | elapsed: 143.9min\n",
      "[Parallel(n_jobs=-1)]: Done 392 tasks      | elapsed: 239.7min\n",
      "[Parallel(n_jobs=-1)]: Done 544 tasks      | elapsed: 259.8min\n",
      "[Parallel(n_jobs=-1)]: Done 712 tasks      | elapsed: 334.0min\n",
      "[Parallel(n_jobs=-1)]: Done 896 tasks      | elapsed: 395.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1203 out of 1275 | elapsed: 483.4min remaining: 28.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1275 out of 1275 | elapsed: 493.2min finished\n"
     ]
    }
   ],
   "source": [
    "args = [dict(m=m, mean_delta=mean_delta) for m, mean_delta in product(ms, mean_deltas)]\n",
    "args = args[task_index::2]\n",
    "args = sum(zip(reversed(args), args), ())[: len(args)]\n",
    "res = Parallel(n_jobs=-1, verbose=7)(delayed(partial_func)(**arg) for arg in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"m\",\n",
    "    \"mean_1\",\n",
    "    \"mean_2\",\n",
    "    \"var_1\",\n",
    "    \"var_2\",\n",
    "    \"mean_delta\",\n",
    "    \"var_delta\",\n",
    "    *[\n",
    "        f\"omni_{metric}_{k}_{test.__name__}\"\n",
    "        for k in n_clusters\n",
    "        for metric in [\"precision\", \"recall\"]\n",
    "        for test in tests\n",
    "    ],\n",
    "    *[\n",
    "        f\"mase_{metric}_{k}_{test.__name__}\"\n",
    "        for k in n_clusters\n",
    "        for metric in [\"precision\", \"recall\"]\n",
    "        for test in tests\n",
    "    ],\n",
    "]\n",
    "res_df = pd.DataFrame(res, columns=cols)\n",
    "res_df.to_csv(\n",
    "    f\"./results/20200409_weighted_correct_nodes_{task_index}.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat([pd.read_csv(f\"./results/20200409_weighted_correct_nodes_{i}.csv\") for i in range(2)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.sort_values(['m', 'mean_delta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.to_csv(\"./results/20200409_weighted_correct_nodes.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
