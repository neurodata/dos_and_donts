{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/j1c/miniconda3/envs/graspy/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.mixture.gaussian_mixture module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.mixture. Anything that cannot be imported from sklearn.mixture is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "from functools import partial\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from graspy.cluster import GaussianCluster\n",
    "from graspy.embed import MultipleASE, OmnibusEmbed\n",
    "from graspy.models import SBMEstimator\n",
    "from graspy.plot import heatmap\n",
    "from graspy.simulations import er_np, sbm\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "from src import generate_truncnorm_sbms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_embeddings(X, Y, method):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str\n",
    "        Must be {'mase', 'omni'}\n",
    "    \"\"\"\n",
    "    stacked = np.vstack([X, Y])\n",
    "\n",
    "    if method == \"mase\":\n",
    "        embedder = MultipleASE(2)\n",
    "        embeddings = embedder.fit_transform(stacked)\n",
    "    elif method == \"omni\":\n",
    "        embedder = OmnibusEmbed(2)\n",
    "        embeddings = embedder.fit_transform(stacked).mean(axis=0)\n",
    "    else:\n",
    "        assert ValueError(\"Invalid embedding method\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def estimate_community(embeddings, true_labels, method, n_clusters):\n",
    "    predicted_labels = GaussianCluster(n_clusters, n_clusters, \"all\").fit_predict(\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    # Label flipping\n",
    "    idx = true_labels == 0\n",
    "    if np.mean(predicted_labels[idx]) < 0.5:\n",
    "        ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "        return predicted_labels, ari\n",
    "    else:\n",
    "        # This is bitwise flipping. Turns all 0s to 1s and 1s to 0s.\n",
    "        # Reason is to make labels consistent across repetitions\n",
    "        # predicted_labels = predicted_labels ^ (predicted_labels & 1 == predicted_labels)\n",
    "        ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "        return predicted_labels, ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_embeddings(X, Y, method):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    method : str\n",
    "        Must be {'mase', 'omni'}\n",
    "    \"\"\"\n",
    "    stacked = np.vstack([X, Y])\n",
    "\n",
    "    if method == \"mase\":\n",
    "        embedder = MultipleASE(2)\n",
    "        embeddings = embedder.fit_transform(stacked)\n",
    "    elif method == \"omni\":\n",
    "        embedder = OmnibusEmbed(2)\n",
    "        embeddings = embedder.fit_transform(stacked).mean(axis=0)\n",
    "    else:\n",
    "        assert ValueError(\"Invalid embedding method\")\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def estimate_community(embeddings, true_labels, method, n_clusters):\n",
    "    predicted_labels = GaussianCluster(n_clusters, n_clusters, \"all\").fit_predict(\n",
    "        embeddings\n",
    "    )\n",
    "\n",
    "    # Label flipping\n",
    "    idx = true_labels == 0\n",
    "    if np.mean(predicted_labels[idx]) < 0.5:\n",
    "        ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "        return predicted_labels, ari\n",
    "    else:\n",
    "        # This is bitwise flipping. Turns all 0s to 1s and 1s to 0s.\n",
    "        # Reason is to make labels consistent across repetitions\n",
    "        # predicted_labels = predicted_labels ^ (predicted_labels & 1 == predicted_labels)\n",
    "        ari = adjusted_rand_score(true_labels, predicted_labels)\n",
    "        return predicted_labels, ari\n",
    "\n",
    "\n",
    "def run_experiment(m, block_1, block_2, mean_1, mean_2, var_1, var_2, n_clusters, reps):\n",
    "    omni_corrects = np.zeros((reps, len(n_clusters) * 2))\n",
    "    mase_corrects = np.zeros((reps, len(n_clusters) * 2))\n",
    "    omni_aris = np.zeros((reps, len(n_clusters)))\n",
    "    mase_aris = np.zeros((reps, len(n_clusters)))\n",
    "\n",
    "    for i in np.arange(reps).astype(int):\n",
    "        pop1, pop2, true_labels = generate_truncnorm_sbms(\n",
    "            m=m,\n",
    "            block_1=block_1,\n",
    "            block_2=block_2,\n",
    "            mean_1=mean_1,\n",
    "            mean_2=mean_2,\n",
    "            var_1=var_1,\n",
    "            var_2=var_2,\n",
    "        )\n",
    "        mase_corrects_tmp = []\n",
    "        omni_corrects_tmp = []\n",
    "        mase_aris_tmp = []\n",
    "        omni_aris_tmp = []\n",
    "        for method in [\"mase\", \"omni\"]:\n",
    "            embeddings = estimate_embeddings(pop1, pop2, method)\n",
    "\n",
    "            for k in n_clusters:\n",
    "                predicted_labels, ari = estimate_community(\n",
    "                    embeddings, true_labels, method, k\n",
    "                )\n",
    "\n",
    "                uniques, counts = np.unique(\n",
    "                    predicted_labels[:block_1], return_counts=True\n",
    "                )\n",
    "                b1_max_label = uniques[np.argmax(counts)]\n",
    "                b1_correct = (predicted_labels[:block_1] == b1_max_label).mean()\n",
    "\n",
    "                uniques, counts = np.unique(\n",
    "                    predicted_labels[block_1:], return_counts=True\n",
    "                )\n",
    "                b2_max_label = uniques[np.argmax(counts)]\n",
    "                b2_correct = (predicted_labels[block_1:] == b2_max_label).mean()\n",
    "\n",
    "                if method == \"mase\":\n",
    "                    mase_corrects_tmp += [b1_correct, b2_correct]\n",
    "                    mase_aris_tmp += [ari]\n",
    "                else:\n",
    "                    omni_corrects_tmp += [b1_correct, b2_correct]\n",
    "                    omni_aris_tmp += [ari]\n",
    "\n",
    "        mase_corrects[i] = mase_corrects_tmp\n",
    "        mase_aris[i] = mase_aris_tmp\n",
    "        omni_corrects[i] = omni_corrects_tmp\n",
    "        omni_aris[i] = omni_aris_tmp\n",
    "\n",
    "    omni_powers = omni_corrects.mean(axis=0)\n",
    "    omni_aris = omni_aris.mean(axis=0)\n",
    "    mase_powers = mase_corrects.mean(axis=0)\n",
    "    mase_aris = mase_aris.mean(axis=0)\n",
    "\n",
    "    to_append = [\n",
    "        m,\n",
    "        mean_1,\n",
    "        mean_2,\n",
    "        var_1,\n",
    "        var_2,\n",
    "        *omni_powers,\n",
    "        *omni_aris,\n",
    "        *mase_powers,\n",
    "        *mase_aris,\n",
    "    ]\n",
    "    return to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(task_index):\n",
    "    task_index = int(task_index)\n",
    "\n",
    "    spacing = 50\n",
    "\n",
    "    block_1 = 25  # different probability\n",
    "    block_2 = 25\n",
    "    mean_1 = 0\n",
    "    mean_2 = 0\n",
    "    var_1 = 1 / 2\n",
    "    var_2s = np.linspace(var_1, 3, spacing + 1)\n",
    "    reps = 50\n",
    "    n_clusters = range(2, 11, 2)\n",
    "    ms = np.linspace(0, 250, spacing + 1)[1:].astype(int)\n",
    "\n",
    "    partial_func = partial(\n",
    "        run_experiment,\n",
    "        block_1=block_1,\n",
    "        block_2=block_2,\n",
    "        mean_1=mean_1,\n",
    "        mean_2=mean_2,\n",
    "        var_1=var_1,\n",
    "        n_clusters=n_clusters,\n",
    "        reps=reps,\n",
    "    )\n",
    "\n",
    "    args = [dict(m=m, var_2=var_2) for m, var_2 in product(ms, var_2s)]\n",
    "    args = sum(zip(reversed(args), args), ())[: len(args)]\n",
    "    args = args[task_index::10]\n",
    "    res = Parallel(n_jobs=-1, verbose=1)(delayed(partial_func)(**arg) for arg in args)\n",
    "\n",
    "    cols = [\n",
    "        \"m\",\n",
    "        \"mean_1\",\n",
    "        \"mean_2\",\n",
    "        \"var_1\", \n",
    "        \"var_2\",\n",
    "        *[f\"omni_correct_nodes_{i}_{k}\" for k in n_clusters for i in range(1, 3)],\n",
    "        *[f\"omni_ari_{k}\" for k in n_clusters],\n",
    "        *[f\"mase_correct_nodes_{i}_{k}\" for k in n_clusters for i in range(1, 3)],\n",
    "        *[f\"mase_ari_{k}\" for k in n_clusters],\n",
    "    ]\n",
    "    res_df = pd.DataFrame(res, columns=cols)\n",
    "    res_df.to_csv(\n",
    "        f\"./results/20200216_weighted_correct_nodes_{task_index}.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spacing = 50\n",
    "\n",
    "block_1 = 25  # different probability\n",
    "block_2 = 25\n",
    "mean_1 = 0\n",
    "mean_2 = 0\n",
    "var_1 = 1 / 2\n",
    "var_2s = np.linspace(var_1, 3, spacing + 1)\n",
    "reps = 50\n",
    "n_clusters = range(2, 11, 2)\n",
    "ms = np.linspace(0, 250, spacing + 1)[1:].astype(int)\n",
    "\n",
    "partial_func = partial(\n",
    "    run_experiment,\n",
    "    block_1=block_1,\n",
    "    block_2=block_2,\n",
    "    mean_1=mean_1,\n",
    "    mean_2=mean_2,\n",
    "    var_1=var_1,\n",
    "    n_clusters=n_clusters,\n",
    "    reps=reps,\n",
    ")\n",
    "\n",
    "args = [dict(m=m, var_2=var_2) for m, var_2 in [(10, 1), (20, 1)]]\n",
    "#args = sum(zip(reversed(args), args), ())[: len(args)]\n",
    "#args = args[task_index::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   54.5s finished\n"
     ]
    }
   ],
   "source": [
    "res = Parallel(n_jobs=-1, verbose=1)(delayed(partial_func)(**arg) for arg in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "        \"m\",\n",
    "        \"mean_1\",\n",
    "        \"mean_2\",\n",
    "    \"var_1\", \"var_2\",\n",
    "        *[f\"omni_correct_nodes_{i}_{k}\" for k in n_clusters for i in range(1, 3)],\n",
    "        *[f\"omni_ari_{k}\" for k in n_clusters],\n",
    "        *[f\"mase_correct_nodes_{i}_{k}\" for k in n_clusters for i in range(1, 3)],\n",
    "        *[f\"mase_ari_{k}\" for k in n_clusters],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[10,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  1,\n",
       "  0.7480000000000002,\n",
       "  0.7032000000000003,\n",
       "  0.5207999999999999,\n",
       "  0.4759999999999999,\n",
       "  0.38800000000000007,\n",
       "  0.3224,\n",
       "  0.34639999999999993,\n",
       "  0.27199999999999996,\n",
       "  0.2872,\n",
       "  0.23200000000000004,\n",
       "  0.005423365609386802,\n",
       "  0.007866329836102536,\n",
       "  0.004932206636692212,\n",
       "  0.00455509133462032,\n",
       "  0.006939228010409423,\n",
       "  0.7320000000000002,\n",
       "  0.6888000000000002,\n",
       "  0.5104000000000001,\n",
       "  0.44560000000000016,\n",
       "  0.4152000000000001,\n",
       "  0.3224000000000001,\n",
       "  0.33199999999999996,\n",
       "  0.26719999999999994,\n",
       "  0.29119999999999996,\n",
       "  0.21679999999999994,\n",
       "  0.015411415840564102,\n",
       "  0.009746755243820944,\n",
       "  0.011433138546085115,\n",
       "  0.006129312185021949,\n",
       "  0.009638855221924238],\n",
       " [20,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  1,\n",
       "  0.7328000000000005,\n",
       "  0.6431999999999998,\n",
       "  0.5472,\n",
       "  0.45280000000000004,\n",
       "  0.43519999999999986,\n",
       "  0.3384,\n",
       "  0.35839999999999994,\n",
       "  0.2648,\n",
       "  0.316,\n",
       "  0.2296,\n",
       "  0.01700248665968446,\n",
       "  0.011564258421260711,\n",
       "  0.01167799309444468,\n",
       "  0.012010283453750846,\n",
       "  0.013237917445687957,\n",
       "  0.7832000000000002,\n",
       "  0.7056000000000001,\n",
       "  0.5552000000000001,\n",
       "  0.42640000000000006,\n",
       "  0.4456,\n",
       "  0.34319999999999995,\n",
       "  0.3855999999999999,\n",
       "  0.2656,\n",
       "  0.33599999999999997,\n",
       "  0.22080000000000005,\n",
       "  0.01871807453024468,\n",
       "  0.027291076811689994,\n",
       "  0.025711107306394126,\n",
       "  0.022532297853402144,\n",
       "  0.018158829410757835]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"m\",\n",
    "    \"p\",\n",
    "    \"delta\",\n",
    "    *[f\"omni_correct_nodes_{i}\" for i in range(1, 3)],\n",
    "    *[f\"mase_correct_nodes_{i}\" for i in range(1, 3)],\n",
    "]\n",
    "res_df = pd.DataFrame(res, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser(description=\"This is a script for running experiments.\")\n",
    "    parser.add_argument(\"task_index\", help=\"SLURM task index\")\n",
    "\n",
    "    result = parser.parse_args()\n",
    "    task_index = result.task_index\n",
    "    main(task_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
